@InProceedings{pmlr-v97-lee19b,
  title = 	 {Functional Transparency for Structured Data: a Game-Theoretic Approach},
  author = 	 {Lee, Guang-He and Jin, Wengong and Alvarez-Melis, David and Jaakkola, Tommi},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {3723--3733},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/lee19b/lee19b.pdf},
  url = 	 {http://proceedings.mlr.press/v97/lee19b.html},
  abstract = 	 {We provide a new approach to training neural models to exhibit transparency in a well-defined, functional manner. Our approach naturally operates over structured data and tailors the predictor, functionally, towards a chosen family of (local) witnesses. The estimation problem is setup as a co-operative game between an unrestricted \emph{predictor} such as a neural network, and a set of \emph{witnesses} chosen from the desired transparent family. The goal of the witnesses is to highlight, locally, how well the predictor conforms to the chosen family of functions, while the predictor is trained to minimize the highlighted discrepancy. We emphasize that the predictor remains globally powerful as it is only encouraged to agree locally with locally adapted witnesses. We analyze the effect of the proposed approach, provide example formulations in the context of deep graph and sequence models, and empirically illustrate the idea in chemical property prediction, temporal modeling, and molecule representation learning.}
}
